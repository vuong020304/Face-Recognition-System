import cv2
import os
import time
import numpy as np
from face_core.detector import FaceDetector
from face_core.gallery import FaceGalleryManager
from face_core.recognizer import FaceRecognizer

# ===== CONSTANTS =====
CAPTURE_INTERVAL = 3  # Chá»¥p má»—i 3 giÃ¢y
RECOGNITION_THRESHOLD = 0.6  # Threshold cho nháº­n dáº¡ng
MAX_FACES_ALLOWED = 1  # Chá»‰ cho phÃ©p 1 khuÃ´n máº·t
WAIT_TIME_AFTER_INPUT = 2  # Äá»£i 2 giÃ¢y sau khi nháº­p tÃªn

def smart_add_person_camera():
    """ThÃªm ngÆ°á»i thÃ´ng minh - tá»± Ä‘á»™ng nháº­n diá»‡n vÃ  há»i tÃªn khi cáº§n"""
    # Khá»Ÿi táº¡o
    detector = FaceDetector()
    gallery_manager = FaceGalleryManager(detector)
    recognizer = FaceRecognizer(detector, gallery_manager, threshold=RECOGNITION_THRESHOLD)
    
    # Má»Ÿ webcam
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ [CAMERA] KhÃ´ng thá»ƒ má»Ÿ webcam")
        return False
    
    print("ğŸ¤– SMART ADD PERSON - Chá»¥p tá»± Ä‘á»™ng")
    print("=" * 50)
    print("ğŸ“· Camera sáº½ tá»± Ä‘á»™ng chá»¥p áº£nh má»—i 3 giÃ¢y")
    print("ğŸ” Há»‡ thá»‘ng sáº½ kiá»ƒm tra ngÆ°á»i Ä‘Ã£ cÃ³ chÆ°a")
    print("âœ‹ Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t")
    print()
    
    last_capture_time = 0
    capture_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ [CAMERA] KhÃ´ng thá»ƒ Ä‘á»c frame tá»« camera")
                break
            
            current_time = time.time()
            
            # Hiá»ƒn thá»‹ frame vá»›i countdown
            display_frame = frame.copy()
            time_until_capture = CAPTURE_INTERVAL - (current_time - last_capture_time)
            
            if time_until_capture > 0:
                countdown = int(time_until_capture) + 1
                cv2.putText(display_frame, f"Next capture in: {countdown}s", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            else:
                cv2.putText(display_frame, "Capturing...", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.putText(display_frame, f"Captured: {capture_count}", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(display_frame, "Press 'q' to quit", 
                       (10, display_frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            cv2.imshow("Smart Add Person", display_frame)
            
            # Auto capture
            if current_time - last_capture_time >= CAPTURE_INTERVAL:
                result = _process_auto_capture(frame, detector, gallery_manager, recognizer)
                if result:
                    capture_count += 1
                    print(f"ğŸ“· Capture #{capture_count}: {result}")
                last_capture_time = current_time
            
            # Check for quit
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print(f"\nâœ… HoÃ n thÃ nh - ÄÃ£ chá»¥p {capture_count} áº£nh")
    
    return True

def _process_auto_capture(frame, detector, gallery_manager, recognizer):
    """Xá»­ lÃ½ auto capture vÃ  quyáº¿t Ä‘á»‹nh thÃªm ngÆ°á»i"""
    # Detect faces
    img_rgb, faces = detector.detect_faces(frame)
    
    if not faces or len(faces) == 0:
        return "KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t"
    
    if len(faces) > MAX_FACES_ALLOWED:
        return f"TÃ¬m tháº¥y {len(faces)} khuÃ´n máº·t - Chá»‰ Ä‘Æ°á»£c {MAX_FACES_ALLOWED} ngÆ°á»i"
    
    # Get embedding cá»§a khuÃ´n máº·t
    face = faces[0]
    embedding = detector.get_face_embedding(img_rgb, face)
    if embedding is None:
        return "KhÃ´ng thá»ƒ trÃ­ch xuáº¥t embedding"
    
    # Nháº­n diá»‡n xem Ä‘Ã£ cÃ³ chÆ°a
    result = recognizer.recognize(embedding)
    person_name = result["result"]
    score = result.get("score", 0)
    
    if person_name != "Unknown":
        # NgÆ°á»i Ä‘Ã£ cÃ³ - thÃªm áº£nh vÃ o gallery
        success, msg = gallery_manager.add_person(person_name, image=img_rgb)
        if success:
            return f"âœ… ThÃªm áº£nh cho {person_name} (score: {score:.3f})"
        else:
            return f"âŒ {msg}"
    else:
        # NgÆ°á»i chÆ°a cÃ³ - há»i tÃªn
        cv2.destroyAllWindows()  # Táº¡m Ä‘Ã³ng camera window
        
        print(f"\nğŸ‘¤ NGÆ¯á»œI Má»šI PHÃT HIá»†N (confidence: {score:.3f})")
        new_name = input("Nháº­p tÃªn ngÆ°á»i nÃ y (Enter Ä‘á»ƒ bá» qua): ").strip()
        
        # Äá»£i má»™t chÃºt trÆ°á»›c khi tiáº¿p tá»¥c
        time.sleep(WAIT_TIME_AFTER_INPUT)
        
        if new_name:
            success, msg = gallery_manager.add_person(new_name, image=img_rgb)
            if success:
                return f"ğŸ‰ Táº¡o má»›i {new_name}"
            else:
                return f"âŒ {msg}"
        else:
            return "â­ï¸ Bá» qua ngÆ°á»i nÃ y"

def add_person_camera():
    """ThÃªm ngÆ°á»i báº±ng camera - cháº¿ Ä‘á»™ thÃ´ng minh"""
    return smart_add_person_camera()

if __name__ == "__main__":
    add_person_camera()