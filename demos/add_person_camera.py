import cv2
import os
import time
import numpy as np
from face_core.detector import FaceDetector
from face_core.gallery import FaceGalleryManager
from face_core.recognizer import FaceRecognizer

# ===== CONSTANTS =====
CAPTURE_INTERVAL = 3  # Ch·ª•p m·ªói 3 gi√¢y
RECOGNITION_THRESHOLD = 0.6  # Threshold cho nh·∫≠n d·∫°ng
MAX_FACES_ALLOWED = 1  # Ch·ªâ cho ph√©p 1 khu√¥n m·∫∑t
WAIT_TIME_AFTER_INPUT = 2  # ƒê·ª£i 2 gi√¢y sau khi nh·∫≠p t√™n

def smart_add_person_camera():
    """Th√™m ng∆∞·ªùi th√¥ng minh - t·ª± ƒë·ªông nh·∫≠n di·ªán v√† tr·∫£ v·ªÅ summary.

    Thu th·∫≠p trong su·ªët phi√™n:
      - existing_adds: dict name -> count (·∫£nh ƒë√£ th√™m cho ng∆∞·ªùi c√≥ s·∫µn)
      - unknown_groups: list of groups, m·ªói group {'embs': [...], 'images': [...]} (ch∆∞a g√°n t√™n)

    Tr·∫£ v·ªÅ m·ªôt dict summary khi ng∆∞·ªùi d√πng nh·∫•n 'q'.
    """
    detector = FaceDetector()
    gallery_manager = FaceGalleryManager(detector)
    recognizer = FaceRecognizer(detector, gallery_manager, threshold=RECOGNITION_THRESHOLD)

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå [CAMERA] Kh√¥ng th·ªÉ m·ªü webcam")
        return None

    print("ü§ñ SMART ADD PERSON - Ch·ª•p t·ª± ƒë·ªông")
    print("=" * 50)
    print("üì∑ Camera s·∫Ω t·ª± ƒë·ªông ch·ª•p ·∫£nh m·ªói 3 gi√¢y")
    print("üîç H·ªá th·ªëng s·∫Ω ki·ªÉm tra ng∆∞·ªùi ƒë√£ c√≥ ch∆∞a")
    print("‚úã Nh·∫•n 'q' ƒë·ªÉ tho√°t")

    last_capture_time = 0
    capture_count = 0

    existing_adds = {}
    unknown_groups = []
    logs = []
    tmp_dir = "tmp_captures"
    if not os.path.exists(tmp_dir):
        os.makedirs(tmp_dir)

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå [CAMERA] Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera")
                break

            current_time = time.time()
            display_frame = frame.copy()
            time_until_capture = CAPTURE_INTERVAL - (current_time - last_capture_time)

            if time_until_capture > 0:
                countdown = int(time_until_capture) + 1
                cv2.putText(display_frame, f"Next capture in: {countdown}s",
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            else:
                cv2.putText(display_frame, "Capturing...",
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            cv2.putText(display_frame, f"Captured: {capture_count}",
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(display_frame, "Press 'q' to quit",
                       (10, display_frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            cv2.imshow("Smart Add Person", display_frame)

            if current_time - last_capture_time >= CAPTURE_INTERVAL:
                res = _process_auto_capture(frame, detector, gallery_manager, recognizer)
                if isinstance(res, dict):
                    capture_count += 1
                    status = res.get('status')
                    msg = res.get('message', '')
                    logs.append(msg)
                    # print status line in the requested format
                    print(f"üì∑ Capture #{capture_count}: {msg}")

                    if status == 'existing':
                        name = res.get('name')
                        if name:
                            existing_adds[name] = existing_adds.get(name, 0) + 1
                    elif status == 'unknown':
                        emb = res.get('embedding')
                        img = res.get('image')
                        placed = False

                        # Save image to temp file to avoid keeping large numpy arrays in summary
                        img_path = None
                        try:
                            if img is not None:
                                bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
                                img_path = os.path.join(tmp_dir, f"capture_{int(time.time()*1000)}_{capture_count}.jpg")
                                cv2.imwrite(img_path, bgr)
                        except Exception:
                            img_path = None

                        if emb is not None:
                            for grp in unknown_groups:
                                mean_emb = grp.get('mean_emb')
                                if mean_emb is None:
                                    continue
                                num = float(np.dot(mean_emb, emb))
                                den = float(np.linalg.norm(mean_emb) * np.linalg.norm(emb) + 1e-8)
                                sim = num / den if den != 0 else 0.0
                                if sim >= 0.7:
                                    grp.setdefault('embs', []).append(emb)
                                    if img_path:
                                        grp.setdefault('images_paths', []).append(img_path)
                                    # update mean embedding
                                    grp['mean_emb'] = np.mean(grp['embs'], axis=0)
                                    placed = True
                                    break
                        if not placed:
                            new_grp = {
                                'embs': [emb] if emb is not None else [],
                                'mean_emb': emb if emb is not None else None,
                                'images_paths': [img_path] if img_path is not None else []
                            }
                            unknown_groups.append(new_grp)
                else:
                    capture_count += 1
                    msg = str(res)
                    logs.append(msg)
                    print(f"üì∑ Capture #{capture_count}: {msg}")

                last_capture_time = current_time

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è D·ª´ng b·ªüi ng∆∞·ªùi d√πng")
    finally:
        cap.release()
        cv2.destroyAllWindows()

    # Build sanitized summary (exclude raw embeddings and numpy arrays)
    sanitized_groups = []
    for grp in unknown_groups:
        sanitized_groups.append({
            'thumb_path': grp.get('images_paths', [None])[0],
            'images_paths': grp.get('images_paths', []),
            'count': len(grp.get('images_paths', []))
        })

    summary = {
        'capture_count': capture_count,
        'existing_adds': existing_adds,
        'unknown_groups': sanitized_groups
    }

    return summary

def _process_auto_capture(frame, detector, gallery_manager, recognizer):
    """X·ª≠ l√Ω auto capture v√† quy·∫øt ƒë·ªãnh th√™m ng∆∞·ªùi.

    Tr·∫£ v·ªÅ dict:
      - {'status':'existing', 'name':..., 'message':...}
      - {'status':'unknown', 'embedding':..., 'image':..., 'message':...}
      - {'status':'no_face'|'multiple'|'error', 'message':...}
    """
    img_rgb, faces = detector.detect_faces(frame)

    if not faces or len(faces) == 0:
        return {"status": "no_face", "message": "Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t"}

    if len(faces) > MAX_FACES_ALLOWED:
        return {"status": "multiple", "message": f"T√¨m th·∫•y {len(faces)} khu√¥n m·∫∑t - Ch·ªâ ƒë∆∞·ª£c {MAX_FACES_ALLOWED} ng∆∞·ªùi"}

    face = faces[0]
    embedding = detector.get_face_embedding(img_rgb, face)
    if embedding is None:
        return {"status": "error", "message": "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t embedding"}

    result = recognizer.recognize(embedding)
    person_name = result.get("result")
    score = result.get("score", 0)

    if person_name and person_name != "Unknown":
        success, msg = gallery_manager.add_person(person_name, image=img_rgb)
        if success:
            return {"status": "existing", "name": person_name, "message": f"Th√™m ·∫£nh cho {person_name} (score: {score:.3f})"}
        else:
            return {"status": "error", "message": msg}
    else:
        return {"status": "unknown", "embedding": embedding, "image": img_rgb, "message": f"Ng∆∞·ªùi m·ªõi ph√°t hi·ªán (score: {score:.3f})"}

def add_person_camera():
    """Th√™m ng∆∞·ªùi b·∫±ng camera - ch·∫ø ƒë·ªô th√¥ng minh"""
    return smart_add_person_camera()

if __name__ == "__main__":
    add_person_camera()